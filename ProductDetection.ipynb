{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProductDetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "zdlCQFyABGy3",
        "7fG1BAIjUP_7",
        "4k8wnPIHwMR4",
        "JUSUqmzUNoST",
        "UM9BsdVmNoSX",
        "dAFVv8JIxoKK",
        "M0RuRDhs_km-",
        "c1GOH259m0fF",
        "vl928RKG8TWY",
        "wvYz3NY1E3Rt",
        "qNhvyoBjpz3t",
        "y57LoZkRNoSZ",
        "zRy8VWHfNoSZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldeluigi/supermarket-2077-product-vision/blob/master/ProductDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVug6f_Gtc5S"
      },
      "source": [
        "# Preliminary Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlCQFyABGy3"
      },
      "source": [
        "## Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQmWhRKUE5oy"
      },
      "source": [
        "!rm -rf sample_data\n",
        "!gdown --id 1fDr4g4wbnSRkuCYyS3wpuJS7Ax22bVB_ -O all.zip\n",
        "!unzip -oq all.zip\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fG1BAIjUP_7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLso_ssrUTuB"
      },
      "source": [
        "import scipy.io\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial.distance import cosine\n",
        "from statistics import mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k8wnPIHwMR4"
      },
      "source": [
        "# Data Visualization Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x36OMLMbXC4"
      },
      "source": [
        "def show_image(img):\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "\n",
        "def show_grayscale_image(img):\n",
        "  show_image(cv2.merge([img, img, img]))\n",
        "\n",
        "def plot_grid(images, columns, show_axis=False, labels=None):\n",
        "  if len(images) == 0 or columns <= 0:\n",
        "    return\n",
        "  height = 1 + math.ceil(len(images) / columns) * 2\n",
        "  width = columns * 4\n",
        "  dpi = max(images[0].shape[0], images[0].shape[1]) // 2\n",
        "  fig = plt.figure(figsize=(width, height), dpi=dpi)\n",
        "  fig.subplots_adjust(hspace=0.4)\n",
        "  for index, img in enumerate(images, start=1):\n",
        "    if 'float' in img.dtype.str:\n",
        "      img = (img * 255).astype('uint8')\n",
        "    sp = fig.add_subplot(math.ceil(len(images) / columns), columns, index)\n",
        "    if not show_axis:\n",
        "      plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    if labels is not None:\n",
        "      l = len(labels)\n",
        "      sp.set_title(labels[(index-1) % l], fontsize=10)\n",
        "    else:\n",
        "      sp.set_title(index, fontsize=10)\n",
        "\n",
        "def dataset_plot_grid(indexes, columns, dataset, draw_item):\n",
        "  fig = plt.figure(figsize=(12, 6), dpi=120)\n",
        "  # fig.subplots_adjust(hspace=0.2)\n",
        "  for index, i_img in enumerate(indexes, start=1):\n",
        "    sp = fig.add_subplot(math.ceil(len(indexes) / columns), columns, index)\n",
        "    row = dataset[i_img]\n",
        "    draw_item(row, sp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifnByBewpq9"
      },
      "source": [
        "# Raw image loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-J_rx58YtO"
      },
      "source": [
        "## Utilities to read raw data from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDIdYTwp8ep0"
      },
      "source": [
        "training_dirname = 'Training'\n",
        "\n",
        "def create_class_label(class_index, class_name):\n",
        "  return class_name\n",
        "\n",
        "def read_classes():\n",
        "  mat = scipy.io.loadmat(os.path.join(training_dirname, 'TrainingClassesIndex.mat'))\n",
        "  raw_classes = list(map(lambda x: x[0], mat['classes'][0]))\n",
        "  classes = map(lambda x: (x[0], create_class_label(*x)), enumerate(raw_classes, start=1))\n",
        "  return dict(classes), dict(enumerate(raw_classes, start=1))\n",
        "\n",
        "def read_training_data(classes):\n",
        "  result = []\n",
        "  for class_index, class_name in classes.items():\n",
        "    dirname_images = os.path.join(training_dirname, class_name)\n",
        "    directory_images = os.fsencode(dirname_images)\n",
        "    for file in os.listdir(directory_images):\n",
        "      img = cv2.imread(os.path.join(dirname_images, os.fsdecode(file)))\n",
        "      img_rgb =  cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      result.append((img_rgb, class_index))\n",
        "  return np.rec.array(result, dtype=[('image', 'O'), ('class_index', 'i4')])\n",
        "\n",
        "def read_store_data(storename):\n",
        "  dirname_anno = os.path.join(storename, 'annotation')\n",
        "  dirname_images = os.path.join(storename, 'images')\n",
        "  directory_anno = os.fsencode(dirname_anno)\n",
        "  directory_images = os.fsencode(dirname_images)\n",
        "\n",
        "  result = []\n",
        "\n",
        "  for file in os.listdir(directory_anno):\n",
        "    filename = os.fsdecode(file)\n",
        "    if filename.endswith(\".mat\"): \n",
        "      mat = scipy.io.loadmat(os.path.join(dirname_anno, filename))\n",
        "      number = re.search(r'^anno.(\\d+).mat$', filename).group(1)\n",
        "      img = cv2.imread(os.path.join(dirname_images, number + '.jpg'))\n",
        "\n",
        "      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      img_annotation = mat['annotation'][0, 0]\n",
        "      bboxes = map(lambda x: x[0], img_annotation[0][0])\n",
        "      labels = map(lambda x: str(x[0][0][0]), img_annotation[1][0])\n",
        "      class_indexes = img_annotation[2][0]\n",
        "      result.append((img_rgb, list(zip(bboxes, labels, class_indexes))))\n",
        "  return np.rec.array(result, dtype=[('image', 'O'), ('items', 'O')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSUqmzUNoST"
      },
      "source": [
        "## Prepare products class dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exz2n1l6NoSW"
      },
      "source": [
        "classes, raw_classes = read_classes()\n",
        "\n",
        "def class_name(class_index):\n",
        "  return classes[class_index] if class_index >= 0 else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3MOBrBrNoSW"
      },
      "source": [
        "## Load training raw images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_yK63lINoSW"
      },
      "source": [
        "products = read_training_data(raw_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdgzi0lC1x3T"
      },
      "source": [
        "## Products visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcLzx8uY10oS"
      },
      "source": [
        "def show_products_with_class(indexes, columns, dataset):\n",
        "  def show_single_product_with_class(row, sp):\n",
        "    plt.axis('off')\n",
        "    plt.imshow(row.image)\n",
        "    sp.set_title(class_name(row.class_index), fontsize=10)\n",
        "  dataset_plot_grid(indexes, columns, dataset, show_single_product_with_class)\n",
        "\n",
        "show_products_with_class(np.random.randint(0, len(products), 6), 3, products)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcedvVCNoSX"
      },
      "source": [
        "# Raw Image preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM9BsdVmNoSX"
      },
      "source": [
        "## Background removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go6lv7htNoSX"
      },
      "source": [
        "# code taken from https://www.kaggle.com/vadbeg/opencv-background-removal and modified\n",
        "\n",
        "def remove_background(img, threshold, use_mask=False):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  _, threshed = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "  kernel_size = round(max(img.shape[0], img.shape[1]) * 0.02)\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "  morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "  cnts = cv2.findContours(morphed, \n",
        "                          cv2.RETR_EXTERNAL,\n",
        "                          cv2.CHAIN_APPROX_SIMPLE)[0] # should be [1] for cv2 version <= 4\n",
        "\n",
        "  cnts = sorted(cnts, key=cv2.contourArea)\n",
        "\n",
        "  mask = cv2.drawContours(threshed, [cnts[-1]], 0, [255], cv2.FILLED)\n",
        "\n",
        "  x, y, w, h = cv2.boundingRect(cnts[-1])\n",
        "\n",
        "  if use_mask:\n",
        "    masked_data = cv2.bitwise_and(img, img, mask=mask)\n",
        "    dst = masked_data[y: y + h, x: x + w]\n",
        "    r, g, b = cv2.split(dst)\n",
        "    alpha = mask[y: y + h, x: x + w]\n",
        "\n",
        "    rgba = [r, g, b, alpha]\n",
        "    dst = cv2.merge(rgba, 4)\n",
        "  else:\n",
        "    dst = img[y: y + h, x: x + w]\n",
        "\n",
        "  return dst\n",
        "\n",
        "n = 777\n",
        "print(f'Index: {n}')\n",
        "print(f'Class: {class_name(products[n].class_index)}')\n",
        "plot_grid([products[n].image, remove_background(products[n].image, 250)], 2, show_axis=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7z17jtMNoSX"
      },
      "source": [
        "## Image resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICMAZEihNoSY"
      },
      "source": [
        "background_color = 255\n",
        "\n",
        "def resize_image(img, size, color=[background_color, background_color, background_color]):\n",
        "  target_w, target_h = size\n",
        "  original_h, original_w, _ = img.shape\n",
        "  target_ar = target_w / target_h\n",
        "  original_ar = original_w / original_h\n",
        "\n",
        "  scale_factor = target_h / original_h if target_ar > original_ar else target_w / original_w\n",
        "  scaled_w = round(original_w * scale_factor)\n",
        "  scaled_h = round(original_h * scale_factor)\n",
        "  scaled_size = (scaled_w, scaled_h)\n",
        "  resized = cv2.resize(img, scaled_size)\n",
        "\n",
        "  delta_h = target_h - scaled_h\n",
        "  delta_w = target_w - scaled_w\n",
        "  top    = delta_h // 2\n",
        "  left   = delta_w // 2\n",
        "  bottom = delta_h - top\n",
        "  right  = delta_w - left\n",
        "\n",
        "  return cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "\n",
        "n = 1315\n",
        "print(f'Index: {n}')\n",
        "print(f'Class: {class_name(products[n].class_index)}')\n",
        "image = products[n].image\n",
        "image = remove_background(image, 250)\n",
        "plot_grid([image, resize_image(image, (400, 400))], 2, show_axis=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LR8gLNUNoSY"
      },
      "source": [
        "## Dataset preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOyo96qdNoSY"
      },
      "source": [
        "### Image cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErK6wz2TNoSY"
      },
      "source": [
        "def clean_image(img):\n",
        "  threshold = 250\n",
        "  img = remove_background(img, threshold)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q7xa0oHNoSY"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnNYgxhcL48z"
      },
      "source": [
        "all_products_images = []\n",
        "for image, class_index in products:\n",
        "  cleaned_image = clean_image(image)\n",
        "  all_products_images.append(cleaned_image)\n",
        "\n",
        "print(len(all_products_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAFVv8JIxoKK"
      },
      "source": [
        "# Computer vision model #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0qeHrFwVIDn"
      },
      "source": [
        "#### Save dataset on disk in order to save memory with ImageDataGenerators\n",
        "Optionally reduce the dataset items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tec-feRdNoSZ"
      },
      "source": [
        "number_of_images_to_save = 1000\n",
        "reduce_dataset = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmiotkwNoSZ"
      },
      "source": [
        "train_data_directory = 'Temp'\n",
        "shutil.rmtree(train_data_directory, ignore_errors=True)\n",
        "\n",
        "index_to_class_map = dict()\n",
        "def index_to_class(index):\n",
        "  # We could search in products for O(n)\n",
        "  # Instead we use a map for O(1)\n",
        "  return index_to_class_map[index]\n",
        "\n",
        "if reduce_dataset:\n",
        "  products_size = number_of_images_to_save\n",
        "  products_to_dump = np.random.choice(products.shape[0], number_of_images_to_save, replace = False)\n",
        "else:\n",
        "  products_size = products.shape[0]\n",
        "  products_to_dump = np.arange(products_size)\n",
        "\n",
        "for index, product_index in tqdm(enumerate(products_to_dump), total=products_size, desc='Writing files...'):\n",
        "  image, class_index = products[product_index]\n",
        "  index_str = f'{index:04d}'\n",
        "  output_dir = os.path.join(train_data_directory, index_str)\n",
        "  Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "  cleaned_image = clean_image(image)\n",
        "  out = cv2.cvtColor(cleaned_image, cv2.COLOR_RGBA2BGRA)\n",
        "  cv2.imwrite(os.path.join(output_dir, f'{index_str}.png'), out)\n",
        "  index_to_class_map[index] = class_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WQgfV_JyV10"
      },
      "source": [
        "## Higher-order algorithms\n",
        "These functions allow to plug-and-play feature extraction and classification and to measure their performances afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsDVZMnqjiXT"
      },
      "source": [
        "def accuracy(extract_features, compute_feature_distance, threshold, n = 100):\n",
        "  actual = []\n",
        "  predicted = []\n",
        "  false_positives = []\n",
        "  false_negatives = []\n",
        "  it = probability_merge(mismatched_images(), matched_images(), p = 0.5)\n",
        "  for _ in tqdm(range(n), total=n, desc='Calculating accuracy...'):\n",
        "    original, transformed, label = next(it)\n",
        "    original_features = extract_features(original)\n",
        "    transformed_features = extract_features(transformed)\n",
        "    distance = compute_feature_distance(original_features, transformed_features)\n",
        "    prediction = 1 if distance > threshold else 0\n",
        "    actual.append(label)\n",
        "    predicted.append(prediction)\n",
        "    if label != prediction:\n",
        "      (false_positives if prediction == 0 else false_negatives).append((original, transformed))\n",
        "  confusion = confusion_matrix(actual, predicted)\n",
        "  print(confusion)\n",
        "  to_be_plotted = []\n",
        "  for original, transformed in false_positives:\n",
        "    to_be_plotted.append(original)\n",
        "    to_be_plotted.append(transformed)\n",
        "  plot_grid(to_be_plotted, 2, labels=['Original', 'False positive'])\n",
        "\n",
        "  to_be_plotted = []\n",
        "  for original, transformed in false_negatives:\n",
        "    to_be_plotted.append(original)\n",
        "    to_be_plotted.append(transformed)\n",
        "  plot_grid(to_be_plotted, 2, labels=['Original', 'False negative'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5yP-PJRMzDe"
      },
      "source": [
        "Prepare (or reset, if rerun) feature cache/database to be queried when classifying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU2HGhCezFRH"
      },
      "source": [
        "feature_cache = None\n",
        "feature_cache_name = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiaWITTaEa0f"
      },
      "source": [
        "def cache_features(extract_features):\n",
        "  global feature_cache, feature_cache_name\n",
        "  if extract_features.__name__ != feature_cache_name:\n",
        "    feature_cache_name = None\n",
        "  if feature_cache is None or feature_cache_name is None:\n",
        "    feature_cache_name = extract_features.__name__\n",
        "    feature_cache = []\n",
        "    for image, index in tqdm(single_images(single_pass = True), desc = 'Creating feature cache...'):\n",
        "      features = extract_features(image)\n",
        "      feature_cache.append((features, index))\n",
        "  return feature_cache\n",
        "\n",
        "def product_classification(img, extract_features, compute_feature_distance):\n",
        "  img_features = extract_features(img)\n",
        "  feature_db = cache_features(extract_features)\n",
        "  distances_iter = map(lambda fc: compute_feature_distance(fc[0], img_features), feature_db)\n",
        "  index, best_distance = min(enumerate(distances_iter), key=lambda x:x[1])\n",
        "  best_match_label = feature_db[index][1]\n",
        "  best_match_index = int(best_match_label)\n",
        "  class_index = index_to_class(best_match_index)\n",
        "  return best_match_index, class_index, class_name(class_index), best_distance\n",
        "\n",
        "def product_classifications(imgs, extract_features, compute_feature_distance):\n",
        "  return list(map(lambda im: product_classification(im, extract_features, compute_feature_distance), imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve7k3hkRyqof"
      },
      "source": [
        "## Model definition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0RuRDhs_km-"
      },
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic-lKJVxmw0c"
      },
      "source": [
        "def rgb_image_to_feature_channels(img):\n",
        "  img_hsv = cv2.cvtColor((img * 255).astype('uint8'), cv2.COLOR_RGB2LAB)\n",
        "  return list(cv2.split(img_hsv))\n",
        "  \n",
        "def create_feature_extractor():\n",
        "  orb = cv2.ORB_create(edgeThreshold=20, nfeatures=100) # https://docs.opencv.org/master/d1/d89/tutorial_py_orb.html\n",
        "  return orb\n",
        "\n",
        "feature_extractor = create_feature_extractor()\n",
        "\n",
        "def extract_features_raw(img):\n",
        "  channels = rgb_image_to_feature_channels(img)\n",
        "  return list(map(lambda x: feature_extractor.detectAndCompute(x, None), channels))\n",
        "\n",
        "def extract_features(img, blur_size = 5):\n",
        "  blurred_img = cv2.GaussianBlur(img, (blur_size, blur_size), 1) if blur_size > 1 else img\n",
        "  return extract_features_raw(blurred_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1GOH259m0fF"
      },
      "source": [
        "### Feature comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrnLslnQnMbl"
      },
      "source": [
        "def create_bf_matcher():\n",
        "  return cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "\n",
        "def create_flann_matcher():\n",
        "  FLANN_INDEX_LSH = 6\n",
        "  index_params = dict(\n",
        "    algorithm = FLANN_INDEX_LSH,\n",
        "    table_number = 6,     # 12\n",
        "    key_size = 12,        # 20\n",
        "    multi_probe_level = 1 # 2\n",
        "  )\n",
        "  search_params = dict(checks = 50)\n",
        "  return cv2.FlannBasedMatcher(index_params, search_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_DnJqjT_knE"
      },
      "source": [
        "def get_keypoint_matches(p, t):\n",
        "  k_1, d_1 = p\n",
        "  k_2, d_2 = t\n",
        "  if d_1 is None or d_2 is None:\n",
        "    return []\n",
        "  matcher = create_bf_matcher()\n",
        "  #matcher = create_flann_matcher()\n",
        "  return matcher.match(d_1, d_2)\n",
        "\n",
        "def get_matches_distances(predictions, targets):\n",
        "  distances = []\n",
        "  for p, t in zip(predictions, targets):\n",
        "    matches = get_keypoint_matches(p, t)\n",
        "    n_matches = len(matches)\n",
        "    if n_matches == 0:\n",
        "      distance = 1e6\n",
        "    else:\n",
        "      # 1 / sum(map(lambda m: 1 / (m.distance ** 2 + epsilon), matches))\n",
        "      distance = sum(filter(lambda d: True, map(lambda m: m.distance, matches))) / n_matches\n",
        "    distances.append(distance)\n",
        "  return distances\n",
        "\n",
        "def cumulative_distance(predictions, targets):\n",
        "  d = get_matches_distances(predictions, targets)\n",
        "  return d[0] ** 2 + d[1] ** 2 + d[2] ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEZtPiNvbYoB"
      },
      "source": [
        "def show_image_comparison(first_img, second_img):\n",
        "  channels_1 = rgb_image_to_feature_channels(first_img)\n",
        "  channels_2 = rgb_image_to_feature_channels(second_img)\n",
        "  f1 = extract_features(first_img)\n",
        "  f2 = extract_features(second_img)\n",
        "  matcher = create_flann_matcher()\n",
        "  \n",
        "  image_grid = []\n",
        "  first_image_int = (first_img * 255).astype('uint8')\n",
        "  second_image_int = (second_img * 255).astype('uint8')\n",
        "  for c1, c2, (k1, d1), (k2, d2) in zip(channels_1, channels_2, f1, f2):\n",
        "    image_grid.append(cv2.drawKeypoints(first_image_int, k1, None))\n",
        "    image_grid.append(cv2.drawKeypoints(second_image_int, k2, None))\n",
        "    matches = matcher.match(d1, d2)\n",
        "    matches = sorted(matches, key = lambda x: x.distance)\n",
        "    image_grid.append(cv2.drawMatches(c1, k1, c2, k2, matches, None, flags=2))\n",
        "  plot_grid(image_grid, 3, labels=['Original', 'Altered', 'Matches on LAB'])\n",
        "\n",
        "show_image_comparison(*next(matched_images()))\n",
        "show_image_comparison(*next(mismatched_images()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YWqM-RD7cp8"
      },
      "source": [
        "def stats(it, n = 1):\n",
        "  results = []\n",
        "  for _ in range(n):\n",
        "    original, transformed = next(it)\n",
        "    original_f = extract_features(original)\n",
        "    transformed_f = extract_features(transformed)\n",
        "    if original_f[1] is None or transformed_f[1] is None:\n",
        "      continue\n",
        "    results.append(cumulative_distance(original_f, transformed_f))\n",
        "  print('\\tAvg:', np.mean(results))\n",
        "  print('\\tMedian:', np.median(results))\n",
        "  print('\\tMax:', np.max(results))\n",
        "  print('\\tMin:', np.min(results))\n",
        "  print('\\tStdev:', np.std(results))\n",
        "\n",
        "print(\"Summary of matched images feature comparison by comulative distance:\")\n",
        "stats(matched_images(), 500)\n",
        "print(\"Summary of mismatched images feature comparison by cumulative distance:\")\n",
        "stats(mismatched_images(), 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl928RKG8TWY"
      },
      "source": [
        "### Feature classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpSpRaVdkxZM"
      },
      "source": [
        "# Create data on which we must find a discriminator\n",
        "def find_discriminator(n = 1000):\n",
        "  X = []\n",
        "  y = []\n",
        "  Xv = []\n",
        "  yv = []\n",
        "  matched = matched_images()\n",
        "  mismatched = mismatched_images()\n",
        "  for i in range(n):\n",
        "    if i < n / 2:\n",
        "      im1, im2 = next(matched)\n",
        "      X.append(get_matches_distances(extract_features(im1), extract_features(im2)))\n",
        "      y.append(0)\n",
        "      im1, im2 = next(matched)\n",
        "      Xv.append(get_matches_distances(extract_features(im1), extract_features(im2)))\n",
        "      yv.append(0)\n",
        "    else:\n",
        "      im1, im2 = next(mismatched)\n",
        "      X.append(get_matches_distances(extract_features(im1), extract_features(im2)))\n",
        "      y.append(1)\n",
        "      im1, im2 = next(mismatched)\n",
        "      Xv.append(get_matches_distances(extract_features(im1), extract_features(im2)))\n",
        "      yv.append(1)\n",
        "  perm = np.random.permutation(len(X))\n",
        "  X = np.asarray(X)[perm]\n",
        "  y = np.asarray(y)[perm]\n",
        "  perm = np.random.permutation(len(X))\n",
        "  Xv = np.asarray(Xv)[perm]\n",
        "  yv = np.asarray(yv)[perm]\n",
        "  lr = LogisticRegression()\n",
        "  clf = lr.fit(X, y)\n",
        "  score = lr.score(Xv, yv)\n",
        "  print(f\"Discriminator accuracy: {score}\")\n",
        "  return clf\n",
        "\n",
        "classifier = find_discriminator(400)\n",
        "\n",
        "def classify_distances(distances):\n",
        "  return classifier.predict_proba([distances])[0][1]\n",
        "\n",
        "def classify_features(predictions, targets):\n",
        "  return classify_distances(get_matches_distances(predictions, targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIXcUiuSTpXz"
      },
      "source": [
        "def stats(it, n = 1):\n",
        "  results = []\n",
        "  for _ in range(n):\n",
        "    original, transformed = next(it)\n",
        "    original_f = extract_features(original)\n",
        "    transformed_f = extract_features(transformed)\n",
        "    if original_f[1] is None or transformed_f[1] is None:\n",
        "      continue\n",
        "    results.append(classify_features(original_f, transformed_f))\n",
        "  print('\\tAvg:', np.mean(results))\n",
        "  print('\\tMedian:', np.median(results))\n",
        "  print('\\tMax:', np.max(results))\n",
        "  print('\\tMin:', np.min(results))\n",
        "  print('\\tStdev:', np.std(results))\n",
        "\n",
        "print(\"Summary of matched images feature comparison by discrimination with probability:\")\n",
        "stats(matched_images(), 500)\n",
        "print(\"Summary of mismatched images feature comparison by discrimination with probability:\")\n",
        "stats(mismatched_images(), 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvYz3NY1E3Rt"
      },
      "source": [
        "### Evaluate performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGwsPYm-E3Rt"
      },
      "source": [
        "accuracy(extract_features, cumulative_distance, 10000, n = 400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FN2GLT8E3Rt"
      },
      "source": [
        "def column(M, c):\n",
        "  return [row[c] for row in M]\n",
        "test_size = 10\n",
        "test_images = list(itertools.islice(single_altered_images(), test_size))\n",
        "predictions = product_classifications(column(test_images, 0), extract_features, cumulative_distance)\n",
        "cm = confusion_matrix(column(test_images, 1), column(predictions, 0))\n",
        "print(\"Accuracy: \", np.trace(cm) / test_size)\n",
        "plot_grid(column(test_images[:20], 0), 5, labels=column(predictions[:20], 2))\n",
        "del test_images, predictions, cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edbd4L5ld4yp"
      },
      "source": [
        "import pandas\n",
        "print(pandas.DataFrame(np.fromiter(map(lambda e: len(e[0][0][0]), feature_cache), dtype='uint32')).describe())\n",
        "del pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pBqJ3JRpjp"
      },
      "source": [
        "# Computer vision model #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd7r2jicbQpD"
      },
      "source": [
        "def extract_features_from_image(img, extractor):\n",
        "  keypoints, descriptors = extractor.detectAndCompute(img, None)\n",
        "  if keypoints is None or descriptors is None:\n",
        "    return [], []\n",
        "  return keypoints, descriptors\n",
        "\n",
        "def extract_features(images):\n",
        "  orb = cv2.ORB_create(nfeatures=150)\n",
        "  return list(map(lambda img: extract_features_from_image(img, orb), images))\n",
        "\n",
        "features = extract_features(all_products_images)\n",
        "descriptors = list(map(lambda f: f[1], features))\n",
        "n = 0\n",
        "print(\"Numero di keypoint estratti dall'immagine\", n, \"=\", len(descriptors[0]))\n",
        "print(\"Numero di descrittori per ogni keypoint =\", len(descriptors[0][0]))\n",
        "print(\"Numero di descrittori estratti in media da ogni immagine\", np.mean(list(map(lambda d: len(d), descriptors))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Up1UGXKxSlI"
      },
      "source": [
        "def create_bovw(features, n_clusters):\n",
        "  kmeans = KMeans(n_clusters = n_clusters, n_init = 1, max_iter = 500, verbose = 1)\n",
        "  all_descriptors = []\n",
        "  for _, desc in features:\n",
        "    all_descriptors.extend(desc)\n",
        "  print('Running KMeans on', len(all_descriptors), 'patterns')\n",
        "  kmeans.fit(all_descriptors)\n",
        "  print(kmeans.labels_)\n",
        "  i = 0\n",
        "  labels = []\n",
        "  for _, desc in features:\n",
        "    curr_label = []\n",
        "    for d in desc:\n",
        "      curr_label.append(kmeans.labels_[i])\n",
        "      i += 1\n",
        "    labels.append(curr_label)\n",
        "  return (kmeans.cluster_centers_, labels)\n",
        "\n",
        "n_clusters = 128\n",
        "bovw, bovw_labels = create_bovw(features, n_clusters)\n",
        "\n",
        "\n",
        "print(\"Numero di visual words =\", len(bovw))\n",
        "print(\"Numero di descrittori per ogni visual word =\", len(bovw[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EKKIStafl7Y"
      },
      "source": [
        "def normalize_histogram(histogram):\n",
        "  sum = np.sum(histogram)\n",
        "  if sum == 0:\n",
        "    return [0.0] * len(histogram)\n",
        "  return [x / sum for x in histogram]\n",
        "\n",
        "def create_histogram_from_labels(n, labels):\n",
        "  histogram = [0] * n\n",
        "  for l in labels:\n",
        "    histogram[l] += 1\n",
        "  return normalize_histogram(histogram)\n",
        "\n",
        "histograms = [create_histogram_from_labels(n_clusters, l) for l in bovw_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8wKf41952Nw"
      },
      "source": [
        "n = np.random.randint(0, len(all_products_images))\n",
        "img = all_products_images[n]\n",
        "keypoints, _ = features[n]\n",
        "labels = bovw_labels[n]\n",
        "keypoints_by_label = {}\n",
        "\n",
        "for k, l in zip(keypoints, labels):\n",
        "  if l not in keypoints_by_label:\n",
        "    keypoints_by_label[l] = []\n",
        "  keypoints_by_label[l].append(k)\n",
        "\n",
        "for l in keypoints_by_label:\n",
        "  [r, g, b] = list(np.random.choice(range(256), size=3))\n",
        "  cv2.drawKeypoints(img, keypoints_by_label[l], img, color = (int(b), int(g), int(r)))\n",
        "\n",
        "print(\"Numero di keypoint =\", len(keypoints))\n",
        "show_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaHqNebNxv4Z"
      },
      "source": [
        "def create_histogram_for_image(img, descriptors, bovw, distance_metric):\n",
        "  #[hist_b, hist_g, hist_r] = cv2.calcHist([img], [0, 1, 2], mask=None, [256], [0, 256])\n",
        "  histogram = [0] * len(bovw)\n",
        "  for d in descriptors:\n",
        "    nearest = 0\n",
        "    nearest_distance = distance_metric(d, bovw[0])\n",
        "    for i in range(1, len(bovw)):\n",
        "      vw = bovw[i]\n",
        "      distance = distance_metric(d, vw)\n",
        "      if distance < nearest_distance:\n",
        "        nearest = i\n",
        "        nearest_distance = distance\n",
        "    histogram[nearest] += 1\n",
        "  return normalize_histogram(histogram)\n",
        "\n",
        "def cosine_distance(x, y):\n",
        "  return cosine(x, y)\n",
        "\n",
        "def euclidean_distance(x, y):\n",
        "  return np.linalg.norm(x - y)\n",
        "\n",
        "def create_histograms(images, features, bovw, show_progress=False):\n",
        "  histograms = []\n",
        "  iterator = zip(images, features)\n",
        "  if show_progress:\n",
        "    iterator = tqdm(iterator, total = len(images), desc = \"calculating histograms...\")\n",
        "  for image, f in iterator:\n",
        "    _, descriptors = f\n",
        "    histogram = create_histogram_for_image(image, descriptors, bovw, euclidean_distance)\n",
        "    histograms.append(histogram)\n",
        "  return histograms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PullAcRB25Z6"
      },
      "source": [
        "nn = NearestNeighbors(n_neighbors=1).fit(histograms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P1aUYU5xxgU"
      },
      "source": [
        "def predict(images, bovw, nn):\n",
        "  image_features = extract_features(images)\n",
        "  histograms = create_histograms(images, image_features, bovw)\n",
        "  distances, indices = nn.kneighbors(histograms)\n",
        "  distances = list(map(lambda x: x[0], distances))\n",
        "  indices = list(map(lambda x: x[0], indices))\n",
        "  return indices, distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNhvyoBjpz3t"
      },
      "source": [
        "# Testing model on stores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtjIpcNK7ap1"
      },
      "source": [
        "store = read_store_data('store2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpsgqbT7Gd-W"
      },
      "source": [
        "def sliding_window(img, size, stride=(0.5, 0.5)):\n",
        "  scale_values=[0.5, 0.3]\n",
        "  height, width, _ = img.shape\n",
        "  aspect_ratio = size[1] / size[0]\n",
        "  for scale in scale_values:\n",
        "    scaled_width = int(width * scale)\n",
        "    scaled_height = int(height * scale)\n",
        "    scaled_img = resize_image(img, (scaled_width, scaled_height))\n",
        "    y_min = 0\n",
        "    while y_min + size[1] < scaled_height:\n",
        "      x_min = 0\n",
        "      while x_min + size[0] < scaled_width:\n",
        "        yield scaled_img[y_min : y_min + size[0] - 1, x_min : x_min + size[1] - 1]\n",
        "        x_min += int(size[0] * stride[0])\n",
        "      y_min += int(size[1] * stride[1])\n",
        "\n",
        "size = (224, 224)\n",
        "n = 20\n",
        "img, _ = store[n]\n",
        "sw_images = list(sliding_window(img, size))\n",
        "indices, _ = predict(sw_images, bovw, nn)\n",
        "predicted_classes = map(lambda i : products[\"class_index\"][i], indices)\n",
        "non_background = list(filter(lambda c : c != 1, predicted_classes))\n",
        "\n",
        "target_class = mode(non_background)\n",
        "print(class_name(target_class))\n",
        "show_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH4hdamIhqU3"
      },
      "source": [
        "test_tea = b'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'\n",
        "import base64\n",
        "with open(\"tea.png\", \"wb\") as fh:\n",
        "    fh.write(base64.decodebytes(test_tea))\n",
        "img = cv2.cvtColor(cv2.imread(\"tea.png\"), cv2.COLOR_BGR2RGB)\n",
        "indices, _ = predict([img], bovw, nn)\n",
        "predicted_class = products[\"class_index\"][indices[0]]\n",
        "print(class_name(predicted_class))\n",
        "show_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBQS19ZqVuJX"
      },
      "source": [
        "## Performance evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Dmyc8MVyXU"
      },
      "source": [
        "from sklearn.utils.extmath import weighted_mode\n",
        "from scipy.stats import mode\n",
        "\n",
        "def predict_with_window(img):\n",
        "  sw_images = list(sliding_window(img, (img.shape[0] // 3, img.shape[1] // 3)))\n",
        "  found_indices, distances = predict(sw_images, bovw, nn)\n",
        "  found_classes = map(lambda i : products[\"class_index\"][i], found_indices)\n",
        "  ignore_background_classes, ignore_background_distances = zip(*filter(lambda c : c[0] != 1, zip(found_classes, distances)))\n",
        "  ignore_background_weights = [1/x for x in ignore_background_distances]\n",
        "  most_voted_class = weighted_mode(ignore_background_classes, ignore_background_weights)[0][0]\n",
        "  return most_voted_class\n",
        "predictions = [predict_with_window(img[0]) for img in store]\n",
        "score = [1 if t[1] == mode([x[2] for x in t[0][1]])[0] else 0 for t in zip(store, predictions)]\n",
        "print(\"Accuracy:\", sum(score) / len(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y57LoZkRNoSZ"
      },
      "source": [
        "# Data Augmentation\n",
        "Augmentation, fetching from disk..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRy8VWHfNoSZ"
      },
      "source": [
        "## 3D rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91PXTIneNoSZ"
      },
      "source": [
        "def image_3D_rotation(img, theta = 0, phi = 0, gamma = 0, dx = 0, dy = 0, dz = 0):\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "      img       : the image data as numpy array\n",
        "      theta     : rotation around the x axis\n",
        "      phi       : rotation around the y axis\n",
        "      gamma     : rotation around the z axis (basically a 2D rotation)\n",
        "      dx        : translation along the x axis\n",
        "      dy        : translation along the y axis\n",
        "      dz        : translation along the z axis (distance to the image)\n",
        "  Output:\n",
        "      image     : the rotated image\n",
        "  \n",
        "  Reference:\n",
        "      1.        : http://stackoverflow.com/questions/17087446/how-to-calculate-perspective-transform-for-opencv-from-rotation-angles\n",
        "      2.        : http://jepsonsblog.blogspot.tw/2012/11/rotation-in-3d-using-opencvs.html\n",
        "      3.        : Code taken from https://github.com/eborboihuc/rotate_3d/blob/master/image_transformer.py\n",
        "  \"\"\"\n",
        "  def deg_to_rad(deg):\n",
        "    return deg * math.pi / 180.0\n",
        "  def get_M(theta, phi, gamma, dx, dy, dz, size, focal):\n",
        "    w = size[0]\n",
        "    h = size[1]\n",
        "    f = focal\n",
        "    # Projection 2D -> 3D matrix\n",
        "    A1 = np.array([ [1, 0, -w/2],\n",
        "                    [0, 1, -h/2],\n",
        "                    [0, 0, 1],\n",
        "                    [0, 0, 1]])\n",
        "    # Rotation matrices around the X, Y, and Z axis\n",
        "    RX = np.array([ [1, 0, 0, 0],\n",
        "                    [0, np.cos(theta), -np.sin(theta), 0],\n",
        "                    [0, np.sin(theta), np.cos(theta), 0],\n",
        "                    [0, 0, 0, 1]])\n",
        "    RY = np.array([ [np.cos(phi), 0, -np.sin(phi), 0],\n",
        "                    [0, 1, 0, 0],\n",
        "                    [np.sin(phi), 0, np.cos(phi), 0],\n",
        "                    [0, 0, 0, 1]])\n",
        "    RZ = np.array([ [np.cos(gamma), -np.sin(gamma), 0, 0],\n",
        "                    [np.sin(gamma), np.cos(gamma), 0, 0],\n",
        "                    [0, 0, 1, 0],\n",
        "                    [0, 0, 0, 1]])\n",
        "    # Composed rotation matrix with (RX, RY, RZ)\n",
        "    R = np.dot(np.dot(RX, RY), RZ)\n",
        "    # Translation matrix\n",
        "    T = np.array([  [1, 0, 0, dx],\n",
        "                    [0, 1, 0, dy],\n",
        "                    [0, 0, 1, dz],\n",
        "                    [0, 0, 0, 1]])\n",
        "    # Projection 3D -> 2D matrix\n",
        "    A2 = np.array([ [f, 0, w/2, 0],\n",
        "                    [0, f, h/2, 0],\n",
        "                    [0, 0, 1, 0]])\n",
        "    # Final transformation matrix\n",
        "    return np.dot(A2, np.dot(T, np.dot(R, A1)))\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "  num_channels = img.shape[2]\n",
        "  rtheta = deg_to_rad(theta)\n",
        "  rphi = deg_to_rad(phi)\n",
        "  rgamma = deg_to_rad(gamma)\n",
        "  d = np.sqrt(height**2 + width**2)\n",
        "  focal = d / (2 * np.sin(rgamma) if np.sin(rgamma) != 0 else 1)\n",
        "  dz = focal\n",
        "  mat = get_M(rtheta, rphi, rgamma, dx, dy, dz, (width, height), focal)\n",
        "  return cv2.warpPerspective(\n",
        "    img.copy(),\n",
        "    mat,\n",
        "    (width, height),\n",
        "    borderValue=(background_color, background_color, background_color),\n",
        "    borderMode=cv2.BORDER_CONSTANT\n",
        "  )\n",
        "\n",
        "def random_spatial_rotation(theta_range, phi_range, gamma_range):\n",
        "  return lambda img: image_3D_rotation(\n",
        "    img, \n",
        "    theta = np.random.randint(theta_range[0], theta_range[1] + 1),\n",
        "    phi = np.random.randint(phi_range[0], phi_range[1] + 1),\n",
        "    gamma = np.random.randint(gamma_range[0], gamma_range[1] + 1)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neTkXKe3NoSa"
      },
      "source": [
        "## Data generator parameters definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlxioavxNoSa"
      },
      "source": [
        "real_datagen = ImageDataGenerator(\n",
        "    data_format = 'channels_last',\n",
        ")\n",
        "\n",
        "augmented_datagen = ImageDataGenerator(\n",
        "    brightness_range = [0.5, 1.2],\n",
        "    width_shift_range = size[0] // 10,\n",
        "    height_shift_range = size[1] // 10,\n",
        "    zoom_range = 0.1,\n",
        "    fill_mode = 'constant',\n",
        "    cval = background_color,\n",
        "    data_format = 'channels_last',\n",
        "    preprocessing_function = random_spatial_rotation(\n",
        "      theta_range = (-20, 20),\n",
        "      phi_range = (-30, 30),\n",
        "      gamma_range = (-10, 10)\n",
        "    )\n",
        ")\n",
        "\n",
        "def create_flow(single_pass = False):\n",
        "  rd = real_datagen.flow_from_directory(\n",
        "    directory = train_data_directory,\n",
        "    target_size = size,\n",
        "    color_mode = 'rgb',\n",
        "    class_mode = 'sparse',\n",
        "    batch_size = 1,\n",
        "    shuffle = True\n",
        "  )\n",
        "  if single_pass:\n",
        "    return itertools.islice(rd, rd.samples)\n",
        "  return rd\n",
        "\n",
        "def flow_to_augmented_tuple(t):\n",
        "  rescale = 1./255\n",
        "  original = t[0][0] * rescale\n",
        "  transformed = augmented_datagen.preprocessing_function(t[0][0])\n",
        "  transformed = augmented_datagen.random_transform(transformed) * rescale\n",
        "  label = t[1][0]\n",
        "  return original, transformed, label\n",
        "\n",
        "def flow_to_tuple(t):\n",
        "  rescale = 1./255\n",
        "  original = t[0][0] * rescale\n",
        "  label = t[1][0]\n",
        "  return original, label\n",
        "\n",
        "def mismatched_images():\n",
        "  flow_1 = create_flow()\n",
        "  flow_2 = create_flow()\n",
        "  while True:\n",
        "    t_1 = next(flow_1)\n",
        "    t_2 = next(flow_2)\n",
        "    if t_1[1][0] != t_2[1][0]:\n",
        "      image, _ = flow_to_tuple(t_1)\n",
        "      _, transformed, _ = flow_to_augmented_tuple(t_2)\n",
        "      yield image, transformed\n",
        "    else:\n",
        "      next(flow_1) # used for misaligning iterators\n",
        "\n",
        "def matched_images(single_pass = False):\n",
        "  flow = create_flow(single_pass)\n",
        "  for original, transformed, _ in map(flow_to_augmented_tuple, flow):\n",
        "    yield original, transformed\n",
        "\n",
        "def single_images(single_pass = False):\n",
        "  flow = create_flow(single_pass)\n",
        "  return map(flow_to_tuple, flow)\n",
        "\n",
        "def single_altered_images(single_pass = False):\n",
        "  flow = create_flow(single_pass)\n",
        "  def tuple_f(t):\n",
        "    _, transformed, label = flow_to_augmented_tuple(t)\n",
        "    return transformed, label\n",
        "  return map(tuple_f, flow)\n",
        "\n",
        "res = []\n",
        "it = matched_images()\n",
        "for _ in range(10):\n",
        "  t = next(it)\n",
        "  res.append(t[0])\n",
        "  res.append(t[1])\n",
        "\n",
        "plot_grid(res, 2, labels=[\"Original\", \"Same, altered\"])\n",
        "\n",
        "res = []\n",
        "it = mismatched_images()\n",
        "for _ in range(10):\n",
        "  t = next(it)\n",
        "  res.append(t[0])\n",
        "  res.append(t[1])\n",
        "\n",
        "plot_grid(res, 2, labels=[\"Original\", \"Other, altered\"])\n",
        "del res, it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO85Ns5VPXEH"
      },
      "source": [
        "def probability_merge(it_1, it_2, p = 0.5):\n",
        "  while True:\n",
        "    rand = np.random.random()\n",
        "    it, label = (it_1, 1) if rand < p else (it_2, 0)\n",
        "    original, transformed = next(it)\n",
        "    yield original, transformed, label\n",
        "\n",
        "it = probability_merge(mismatched_images(), matched_images(), p = 0.5)\n",
        "res = []\n",
        "for _ in range(20):\n",
        "  t = next(it)\n",
        "  res.append(t[0])\n",
        "  res.append(t[1])\n",
        "\n",
        "plot_grid(res, 2, labels=[\"First\", \"Second\"])\n",
        "del res, it"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}