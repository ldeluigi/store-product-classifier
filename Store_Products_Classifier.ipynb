{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Store Products Classifier.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "IifnByBewpq9",
        "Wdgzi0lC1x3T",
        "czcedvVCNoSX"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldeluigi/supermarket-2077-product-vision/blob/master/Store_Products_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYAtcMOAGkIh"
      },
      "source": [
        "# Preliminary Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxTxAAg1bAy"
      },
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQmWhRKUE5oy"
      },
      "source": [
        "!rm -rf sample_data\n",
        "!gdown --id 1C-9gj15K2d7nuwgxbE9cZ5lwUpAliLrA -O all.zip # Old dataset: 1fDr4g4wbnSRkuCYyS3wpuJS7Ax22bVB_\n",
        "!unzip -oq all.zip\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeC7G1B41d8O"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn9JWrAq4DpP"
      },
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCfHNlAi1f6J"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwPgf35b33UA"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import shutil\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.utils.extmath import weighted_mode\n",
        "from sklearn.metrics.pairwise import chi2_kernel\n",
        "from scipy.stats import mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k8wnPIHwMR4"
      },
      "source": [
        "# Data Visualization Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x36OMLMbXC4"
      },
      "source": [
        "def show_image(img):\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "\n",
        "def show_grayscale_image(img):\n",
        "  show_image(cv2.merge([img, img, img]))\n",
        "\n",
        "def plot_grid(images, columns, show_axis=False, labels=None):\n",
        "  if len(images) == 0 or columns <= 0:\n",
        "    return\n",
        "  height = 1 + math.ceil(len(images) / columns) * 2\n",
        "  width = columns * 4\n",
        "  dpi = max(images[0].shape[0], images[0].shape[1]) // 2\n",
        "  fig = plt.figure(figsize=(width, height), dpi=dpi)\n",
        "  fig.subplots_adjust(hspace=0.4)\n",
        "  for index, img in enumerate(images, start=1):\n",
        "    if 'float' in img.dtype.str:\n",
        "      img = (img * 255).astype('uint8')\n",
        "    sp = fig.add_subplot(math.ceil(len(images) / columns), columns, index)\n",
        "    if not show_axis:\n",
        "      plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    if labels is not None:\n",
        "      l = len(labels)\n",
        "      sp.set_title(labels[(index-1) % l], fontsize=10)\n",
        "    else:\n",
        "      sp.set_title(index, fontsize=10)\n",
        "\n",
        "def bar_plot(ax, data, colors=None, total_width=0.5, single_width=1, legend=True):\n",
        "  if colors is None:\n",
        "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "  n_bars = len(data)\n",
        "  bar_width = total_width / n_bars\n",
        "  bars = []\n",
        "\n",
        "  for i, (name, values) in enumerate(data.items()):\n",
        "    x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
        "    for x, y in enumerate(values):\n",
        "      bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)], )\n",
        "    bars.append(bar[0])\n",
        "    \n",
        "  if legend:\n",
        "    ax.legend(bars, data.keys())\n",
        "\n",
        "def plot_histogram(histogram):\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.set_size_inches(21, 9)\n",
        "  fig.set_dpi(120)\n",
        "  bar_plot(ax, { '0': histogram }, legend=False)\n",
        "  plt.show()\n",
        "\n",
        "def plot_histograms(histograms):\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.set_size_inches(21 * len(histograms), 9)\n",
        "  fig.set_dpi(120)\n",
        "  bar_plot(ax, { str(k+1): v for k, v in enumerate(histograms) }, legend=True)\n",
        "  plt.show()\n",
        "\n",
        "def dataset_plot_grid(indexes, columns, dataset, draw_item):\n",
        "  fig = plt.figure(figsize=(12, 6), dpi=120)\n",
        "  # fig.subplots_adjust(hspace=0.2)\n",
        "  for index, i_img in enumerate(indexes, start=1):\n",
        "    sp = fig.add_subplot(math.ceil(len(indexes) / columns), columns, index)\n",
        "    row = dataset[i_img]\n",
        "    draw_item(row, sp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifnByBewpq9"
      },
      "source": [
        "# Raw image loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c-J_rx58YtO"
      },
      "source": [
        "## Utilities to read raw data from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOtmBXC5o3G"
      },
      "source": [
        "def remove_prefix(text, prefix):\n",
        "  if text.startswith(prefix):\n",
        "    return text[len(prefix):]\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDIdYTwp8ep0"
      },
      "source": [
        "training_dirname = 'Training'\n",
        "store_dirname = 'Store'\n",
        "store_csv = os.path.join(store_dirname, 'store.csv')\n",
        "\n",
        "def create_class_label(class_index, class_name):\n",
        "  return class_name\n",
        "\n",
        "def read_classes():\n",
        "  classes = set()\n",
        "  for root, dirs, files in os.walk(training_dirname):\n",
        "    if len(files) > 0:\n",
        "      classes.add(remove_prefix(root, training_dirname + os.path.sep))\n",
        "  classes = sorted(classes)\n",
        "  return {k: v for k, v in enumerate(classes)}\n",
        "\n",
        "\n",
        "def read_training_data(classes):\n",
        "  images_by_index = {}\n",
        "  for class_index, class_name in classes.items():\n",
        "    dirname_images = os.path.join(training_dirname, class_name)\n",
        "    directory_images = os.fsencode(dirname_images)\n",
        "    for fname in os.listdir(directory_images):\n",
        "      image_index = int(fname[:-4])\n",
        "      img = cv2.imread(os.path.join(dirname_images, os.fsdecode(fname)))\n",
        "      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      images_by_index[image_index] = (img_rgb, class_index)\n",
        "  return [images_by_index[i][0] for i in range(len(images_by_index))], [images_by_index[i][1] for i in range(len(images_by_index))]\n",
        "\n",
        "def read_store_data():\n",
        "  store_images = {}\n",
        "  store_data = {}\n",
        "  with open(store_csv, 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "      image_index = int(row['image_index'])\n",
        "      bbox = json.loads(row['bounding_box'])\n",
        "      product_label = int(row['product_label'])\n",
        "      if image_index not in store_data:\n",
        "        store_data[image_index] = []\n",
        "      store_data[image_index].append((bbox, product_label))\n",
        "  for fname in os.listdir(store_dirname):\n",
        "    if os.path.isfile(os.path.join(store_dirname, fname)) and fname.endswith('.jpg'):\n",
        "      image_index = int(fname[:-4])\n",
        "      store_images[image_index] = cv2.cvtColor(cv2.imread(os.path.join(store_dirname, fname)), cv2.COLOR_BGR2RGB)\n",
        "  store_images = [v for k, v in sorted(store_images.items(), key=lambda item: item[0])]\n",
        "  store_data = [[] if k not in store_data else store_data[k] for k in range(len(store_images))]\n",
        "  return store_images, store_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSUqmzUNoST"
      },
      "source": [
        "## Prepare products class dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exz2n1l6NoSW"
      },
      "source": [
        "classes = read_classes()\n",
        "\n",
        "def class_name(class_index):\n",
        "  return classes[class_index] if class_index >= 0 else None\n",
        "\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3MOBrBrNoSW"
      },
      "source": [
        "## Load training raw images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_yK63lINoSW"
      },
      "source": [
        "products, products_classes = read_training_data(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdgzi0lC1x3T"
      },
      "source": [
        "## Products visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcLzx8uY10oS"
      },
      "source": [
        "def show_products_with_class(indexes, columns, dataset):\n",
        "  def show_single_product_with_class(row, sp):\n",
        "    img, class_index = row\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    sp.set_title(class_name(class_index), fontsize=10)\n",
        "  dataset_plot_grid(indexes, columns, dataset, show_single_product_with_class)\n",
        "\n",
        "show_products_with_class(np.random.randint(0, len(products), 6), 3, list(zip(products, products_classes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcedvVCNoSX"
      },
      "source": [
        "# Raw Image preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM9BsdVmNoSX"
      },
      "source": [
        "## Dataset filtering and initial preprocessing\n",
        "\n",
        "The initial preprocessing and filtering (dataset reduction) was done with the following notebook hosted on colab:\n",
        "\n",
        "https://colab.research.google.com/drive/1kw36rUwx4lOgRAGMTywGsh0AtmVwVPAO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7z17jtMNoSX"
      },
      "source": [
        "## Image resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICMAZEihNoSY"
      },
      "source": [
        "background_color = 255\n",
        "\n",
        "def pad_image(img, size, color=[background_color, background_color, background_color]):\n",
        "  target_w, target_h = size\n",
        "  original_h, original_w, _ = img.shape\n",
        "  target_ar = target_w / target_h\n",
        "  original_ar = original_w / original_h\n",
        "\n",
        "  scale_factor = target_h / original_h if target_ar > original_ar else target_w / original_w\n",
        "  scaled_w = round(original_w * scale_factor)\n",
        "  scaled_h = round(original_h * scale_factor)\n",
        "  scaled_size = (scaled_w, scaled_h)\n",
        "  resized = cv2.resize(img, scaled_size)\n",
        "\n",
        "  delta_h = target_h - scaled_h\n",
        "  delta_w = target_w - scaled_w\n",
        "  top    = delta_h // 2\n",
        "  left   = delta_w // 2\n",
        "  bottom = delta_h - top\n",
        "  right  = delta_w - left\n",
        "\n",
        "  return cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "\n",
        "def resize_image(img, max_dim):\n",
        "  original_h, original_w, _ = img.shape\n",
        "  scale_factor = max_dim / original_h if original_h > original_w else max_dim / original_w\n",
        "  scaled_w = round(original_w * scale_factor)\n",
        "  scaled_h = round(original_h * scale_factor)\n",
        "  scaled_size = (scaled_w, scaled_h)\n",
        "  resized = cv2.resize(img, scaled_size)\n",
        "  return resized\n",
        "\n",
        "n = 1000\n",
        "print(f'Index: {n}')\n",
        "print(f'Class: {class_name(products_classes[n])}')\n",
        "plot_grid([products[n], resize_image(products[n], 200), products[n], pad_image(products[n], (200, 200))], 2, show_axis=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LR8gLNUNoSY"
      },
      "source": [
        "## Dataset preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOyo96qdNoSY"
      },
      "source": [
        "### Image cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErK6wz2TNoSY"
      },
      "source": [
        "def preprocess_image(img):\n",
        "  img = resize_image(img, 256)\n",
        "  #img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  return img\n",
        "\n",
        "def clean_image(img):\n",
        "  #img = pad_image(img, (256, 256))\n",
        "  img = preprocess_image(img)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q7xa0oHNoSY"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnNYgxhcL48z"
      },
      "source": [
        "all_products_images = []\n",
        "for image, class_index in zip(products, products_classes):\n",
        "  cleaned_image = clean_image(image)\n",
        "  all_products_images.append(cleaned_image)\n",
        "\n",
        "print(len(all_products_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pBqJ3JRpjp"
      },
      "source": [
        "# Computer vision model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvNmVKuTVsdo"
      },
      "source": [
        "## Utilities setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4WghAhVvK3d"
      },
      "source": [
        "### Pickle setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7RgW3eMt7QK"
      },
      "source": [
        "import pickle\n",
        "model_file_name = 'model.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2dEn3mVy1x2"
      },
      "source": [
        "### Distance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq7JO-R7y1Yf"
      },
      "source": [
        "def cosine_distance(x, y):\n",
        "  return cosine(x, y)\n",
        "\n",
        "def euclidean_distance(x, y):\n",
        "  return np.linalg.norm(x - y)\n",
        "\n",
        "def chi2_distance(x, y):\n",
        "  return 1 - chi2_kernel([x], [y], gamma = 0.3)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo5zfyJavWQq"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd7r2jicbQpD"
      },
      "source": [
        "def extract_dense_keypoints(img, extractor):\n",
        "  patch_sizes = [4, 8, 16]\n",
        "  for z in patch_sizes:\n",
        "    for x in range(0, img.shape[1], 2 * z):\n",
        "      for y in range(0, img.shape[0], 2 * z):\n",
        "        yield cv2.KeyPoint(x, y, z, _class_id=0)\n",
        "\n",
        "def extract_keypoints(img, extractor):\n",
        "  return extractor.detect(img)\n",
        "\n",
        "def extract_descriptors_from_image(img, extractor, dense=False):\n",
        "  if dense:\n",
        "    method = extract_dense_keypoints\n",
        "  else:\n",
        "    method = extract_keypoints\n",
        "  keypoints = list(method(img, extractor))\n",
        "  keypoints, descriptors = extractor.compute(img, keypoints)\n",
        "  if descriptors is None:\n",
        "    return [], []\n",
        "  return keypoints, descriptors\n",
        "\n",
        "def extract_descriptors(images, extractor, show_progress=False):\n",
        "  img_iterator = tqdm(images, total=len(images)) if show_progress else images\n",
        "  return [extract_descriptors_from_image(img, extractor)[1] for img in img_iterator]\n",
        "\n",
        "extractor = cv2.SIFT_create(nfeatures = 1000)\n",
        "descriptors = extract_descriptors(all_products_images, extractor, show_progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuewGsBPqhiB"
      },
      "source": [
        "print(\"Numero di keypoint estratti in totale :\", sum([len(d) for d in descriptors]))\n",
        "print(\"Numero di componenti del descrittore per ogni keypoint :\", len(descriptors[n][0]))\n",
        "print(\"Numero di descrittori estratti in media da ogni immagine :\", np.mean(list(map(lambda d: len(d), descriptors))))\n",
        "print()\n",
        "\n",
        "# Show keypoints on image\n",
        "def show_keypoints(img, extractor):\n",
        "  img = img.copy()\n",
        "  keypoints, _ = extract_descriptors_from_image(img, extractor)\n",
        "  show_image(cv2.drawKeypoints(img, keypoints, img, color=(255,255,0)))\n",
        "\n",
        "n = 420\n",
        "print(\"Numero di keypoint estratti dall'immagine\", n, \":\", len(descriptors[n]))\n",
        "print(\"Posizioni dei keypoint dell'immagine\", n, \":\")\n",
        "show_keypoints(all_products_images[n], extractor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9bTcFijvfqA"
      },
      "source": [
        "## Feature clusterization into Bag of Visual Words histograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvPZFGElvn3x"
      },
      "source": [
        "### Compute and save on disk\n",
        "Execute the 'Load model from disk' to skip this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Up1UGXKxSlI"
      },
      "source": [
        "def create_bovw(descriptors, n_clusters, kmeans_max_iter = 150):\n",
        "  termination_criteria = (cv2.TERM_CRITERIA_MAX_ITER, kmeans_max_iter, 0.0)\n",
        "  descriptors_flat = []\n",
        "  for image_descriptors in descriptors:\n",
        "    descriptors_flat.extend(image_descriptors)\n",
        "  descriptors_as_nparray = np.array(descriptors_flat, dtype = np.float32)\n",
        "  compactness, labels, centers = cv2.kmeans(descriptors_as_nparray, n_clusters, None, termination_criteria, 1, cv2.KMEANS_RANDOM_CENTERS)\n",
        "  next_first_label_index = 0\n",
        "  labels_grouped_by_image = []\n",
        "  for image_descriptors in descriptors:\n",
        "    curr_labels = []\n",
        "    count = len(image_descriptors)\n",
        "    for i in range(next_first_label_index, next_first_label_index + count):\n",
        "      curr_labels.append(labels[i][0])\n",
        "    next_first_label_index += count\n",
        "    labels_grouped_by_image.append(curr_labels)\n",
        "  return [[float(x) for x in vw] for vw in centers], labels_grouped_by_image, compactness\n",
        "\n",
        "n_clusters = 256\n",
        "bovw, bovw_labels, compactness = create_bovw(descriptors, n_clusters)\n",
        "\n",
        "print(\"Compattezza =\", compactness)\n",
        "print(\"Numero di visual words =\", len(bovw))\n",
        "print(\"Numero di descrittori per ogni visual word =\", len(bovw[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ_nyf6hWGKa"
      },
      "source": [
        "#### Histogram functions definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EKKIStafl7Y"
      },
      "source": [
        "def normalize_histogram(histogram):\n",
        "  sum = np.sum(histogram)\n",
        "  if sum == 0:\n",
        "    return [0.0] * len(histogram)\n",
        "  return [x / sum for x in histogram]\n",
        "\n",
        "def create_histogram_for_image(descriptors, bovw, bovw_distance_metric):\n",
        "  histogram = [0] * len(bovw)\n",
        "  for d in descriptors:\n",
        "    nearest = 0\n",
        "    nearest_distance = bovw_distance_metric(d, bovw[0])\n",
        "    for i in range(1, len(bovw)):\n",
        "      vw = bovw[i]\n",
        "      distance = bovw_distance_metric(d, vw)\n",
        "      if distance < nearest_distance:\n",
        "        nearest = i\n",
        "        nearest_distance = distance\n",
        "    histogram[nearest] += 1\n",
        "  return normalize_histogram(histogram)\n",
        "\n",
        "def create_histograms(descriptors, bovw, show_progress=False):\n",
        "  histograms = []\n",
        "  iterator = descriptors\n",
        "  if show_progress:\n",
        "    iterator = tqdm(iterator, total = len(descriptors), desc = \"Calculating histograms...\")\n",
        "  for descriptors in iterator:\n",
        "    histogram = create_histogram_for_image(descriptors, bovw, euclidean_distance)\n",
        "    histograms.append(histogram)\n",
        "  return histograms\n",
        "\n",
        "def create_histogram_from_labels(n_clusters, labels):\n",
        "  histogram = [0] * n_clusters\n",
        "  for l in labels:\n",
        "    histogram[l] += 1\n",
        "  return normalize_histogram(histogram)\n",
        "\n",
        "def create_histograms_from_labels(n_clusters, labels):\n",
        "  return [create_histogram_from_labels(n_clusters, l) for l in labels]\n",
        "\n",
        "def compute_histograms(images, bovw, extractor, show_progress=False):\n",
        "  images = [preprocess_image(img) for img in images]\n",
        "  image_descriptors = extract_descriptors(images, extractor)\n",
        "  return create_histograms(image_descriptors, bovw, show_progress=show_progress)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS5s3ksYUVbs"
      },
      "source": [
        "#### Compute histograms look-up table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRflOVuVwZr5"
      },
      "source": [
        "histograms = create_histograms_from_labels(n_clusters, bovw_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMSU6jRcnHcl"
      },
      "source": [
        "#### Save model on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0nT5jvlnF9B"
      },
      "source": [
        "with open(model_file_name, 'wb') as model_file:\n",
        "  data = {\n",
        "    'histograms': histograms,\n",
        "    'bovw': bovw,\n",
        "    'bovw_labels': bovw_labels,\n",
        "    'n_clusters': n_clusters\n",
        "  }\n",
        "  pickle.dump(data, model_file, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfxowTbpnZcX"
      },
      "source": [
        "## Load model from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbvAvoGdndBR"
      },
      "source": [
        "with open(model_file_name, 'rb') as model_file:\n",
        "  data = pickle.load(model_file)\n",
        "  histograms = data['histograms']\n",
        "  bovw = data['bovw']\n",
        "  bovw_labels = data['bovw_labels']\n",
        "  n_clusters = data['n_clusters']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj95b5pfx4mY"
      },
      "source": [
        "## Histogram and keypoints visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8wKf41952Nw"
      },
      "source": [
        "n = np.random.randint(0, len(all_products_images))\n",
        "img = all_products_images[n]\n",
        "keypoints, _ = extract_descriptors_from_image(img, extractor)\n",
        "labels = bovw_labels[n]\n",
        "keypoints_by_label = {}\n",
        "\n",
        "for k, l in zip(keypoints, labels):\n",
        "  if l not in keypoints_by_label:\n",
        "    keypoints_by_label[l] = []\n",
        "  keypoints_by_label[l].append(k)\n",
        "\n",
        "for l in keypoints_by_label:\n",
        "  [r, g, b] = list(np.random.choice(range(256), size=3))\n",
        "  cv2.drawKeypoints(img, keypoints_by_label[l], img, color = (int(b), int(g), int(r)))\n",
        "\n",
        "print(\"Numero di keypoint =\", len(keypoints))\n",
        "show_image(resize_image(img, 256))\n",
        "print(\"Histogram: \")\n",
        "plot_histogram(histograms[n])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNhvyoBjpz3t"
      },
      "source": [
        "# Testing model on stores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P1aUYU5xxgU"
      },
      "source": [
        "def predict(images, bovw, nn, extractor, show_progress=False):\n",
        "  image_histograms = compute_histograms(images, bovw, extractor, show_progress=show_progress)\n",
        "  distances, indices = nn.kneighbors(image_histograms)\n",
        "  return distances, indices\n",
        "\n",
        "k = 10\n",
        "nn = NearestNeighbors(n_neighbors=k, metric=chi2_distance).fit(histograms) # metric=euclidean_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3TAs8w23qJL"
      },
      "source": [
        "store_images, store_bounding_boxes = read_store_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7fFh7gAx2dh"
      },
      "source": [
        "## Tests on cropped store images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kknNxePhyLqe"
      },
      "source": [
        "def crop_bounding_boxes(store_images, bounding_boxes):\n",
        "  cropped_images = []\n",
        "  labels = []\n",
        "  for store_image_raw, bboxes in zip(store_images, bounding_boxes):\n",
        "    store_image = store_image_raw\n",
        "    for bbox, label in bboxes:\n",
        "      [xmin, xmax, ymin, ymax] = bbox\n",
        "      #print(ymin, ymax, xmin, xmax)\n",
        "      xmin, xmax = int(xmin * store_image.shape[1]), int(xmax * store_image.shape[1])\n",
        "      ymin, ymax = int(ymin * store_image.shape[0]), int(ymax * store_image.shape[0])\n",
        "      cropped_images.append(store_image[ymin:ymax, xmin:xmax])\n",
        "      labels.append(label)\n",
        "  return cropped_images, labels\n",
        "\n",
        "cropped_images, cropped_images_labels = crop_bounding_boxes(store_images[:20], store_bounding_boxes[:20])\n",
        "plot_grid([resize_image(i, 256) for i in cropped_images[:12]], 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXzBdkXtVZAE"
      },
      "source": [
        "distances, predictions = predict(cropped_images, bovw, nn, extractor, show_progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sq6UBu2Aj8_"
      },
      "source": [
        "total = len(predictions)\n",
        "category_hit = 0\n",
        "product_hit = 0\n",
        "category_hit_indexes = []\n",
        "category_miss_indexes = []\n",
        "product_hit_indexes = []\n",
        "product_miss_indexes = []\n",
        "\n",
        "\n",
        "for index, label, prediction, distance_vector in zip(range(total), cropped_images_labels, predictions, distances):\n",
        "  weights = [1 / (d + 1e-5)  for d in distance_vector]\n",
        "  predicted_product = prediction[0]\n",
        "  predicted_classes = [products_classes[p] for p in prediction]\n",
        "  most_voted_class = weighted_mode(predicted_classes, weights)[0][0]\n",
        "  #print(products_classes[label], predicted_classes, weights, \"->\", most_voted_class)\n",
        "  if label == predicted_product:\n",
        "    product_hit += 1\n",
        "    product_hit_indexes.append(index)\n",
        "  else:\n",
        "    product_miss_indexes.append(index)\n",
        "  if products_classes[label] == most_voted_class:\n",
        "    category_hit += 1\n",
        "    category_hit_indexes.append(index)\n",
        "  else:\n",
        "    category_miss_indexes.append(index)\n",
        "\n",
        "print('Numero totale di esempi:', total)\n",
        "print('Numero di classificazioni di prodotto corrette:', product_hit)\n",
        "print('Numero di classificazioni di prodotto errate:', total - product_hit)\n",
        "print('Accuratezza di prodotto:', (product_hit / total) * 100, '%')\n",
        "print('Numero di classificazioni di categoria corrette:', category_hit)\n",
        "print('Numero di classificazioni di categoria errate:', total - category_hit)\n",
        "print('Accuratezza di categoria:', (category_hit / total) * 100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90gNNrT32Jxz"
      },
      "source": [
        "def compare_histograms(n):\n",
        "  cropped_bbox = cropped_images[n]\n",
        "  label = cropped_images_labels[n]\n",
        "\n",
        "  original_product_image = all_products_images[label]\n",
        "  blurred = cv2.GaussianBlur(original_product_image, (3, 3), 0)\n",
        "\n",
        "  images_to_compare = [cropped_bbox, original_product_image, blurred]\n",
        "  histograms_to_compare = compute_histograms(images_to_compare, bovw, extractor)\n",
        "  plot_grid(images_to_compare, 4)\n",
        "  plot_histograms(histograms_to_compare)\n",
        "  \n",
        "compare_histograms(101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTSwxSjEx7lG"
      },
      "source": [
        "## Tests on raw store images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpsgqbT7Gd-W"
      },
      "source": [
        "def sliding_window(img):\n",
        "  divide_wh = [(3, 2, 1, 1)]\n",
        "  for wd, hd, ws, hs in divide_wh:\n",
        "    window_w = img.shape[1] / wd\n",
        "    window_h = img.shape[0] / hd\n",
        "    for hi in range(0, hd, hs):\n",
        "      y_min = int(hi * window_h)\n",
        "      y_max = int(y_min + window_h)\n",
        "      for wi in range(0, wd, ws):\n",
        "        x_min = int(wi * window_w)\n",
        "        x_max = int(x_min + window_w)\n",
        "        #print(\"Shape:\", img.shape, \"Window division:\", (hd, wd),\"Window index: \", (hi, wi), \"Pixel range:\", (y_min, x_min), (y_max, x_max))\n",
        "        window = img[y_min:y_max, x_min:x_max]\n",
        "        yield window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBQS19ZqVuJX"
      },
      "source": [
        "### Performance evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Dmyc8MVyXU"
      },
      "source": [
        "def predict_with_window(img, bovw, classifier, extractor):\n",
        "  sw_images = list(sliding_window(img))\n",
        "  distances, indices = predict(sw_images, bovw, classifier, extractor)\n",
        "  #print(indices)\n",
        "  votes = {}\n",
        "  for vote_indexes, vote_distances in zip(indices, distances):\n",
        "    for vote_index, vote_distance in zip(map(lambda i: products_classes[i], vote_indexes), vote_distances):\n",
        "      if vote_index != 0: # Skip background\n",
        "        vote_weight = 1 / (vote_distance + 1e-20)\n",
        "        if vote_index not in votes:\n",
        "          votes[vote_index] = 0  \n",
        "        votes[vote_index] += vote_weight\n",
        "  return sorted(votes.items(), key=lambda item: item[1], reverse=True)[0][0]\n",
        "\n",
        "\n",
        "\n",
        "predictions = [predict_with_window(img, bovw, nn, extractor) for img in tqdm(store_images, total=len(store_images))]\n",
        "score = [1 if prediction == store_class else 0 for store_class, prediction in zip(store_classes, predictions)]\n",
        "print(\"Accuracy:\", sum(score) / len(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygvisNJ8vN5E"
      },
      "source": [
        "sw_images = list(sliding_window(store_images[0]))\n",
        "image_descriptors = extract_descriptors(sw_images, extractor)\n",
        "image_histograms = create_histograms(image_descriptors, bovw, show_progress=True)\n",
        "print(image_descriptors)\n",
        "print(len(image_descriptors[0]))\n",
        "# print(predict(sw_images, bovw, nn, extractor, show_progress=False))\n",
        "\n",
        "print(histograms[100])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}